{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.735545Z",
     "iopub.status.busy": "2025-03-15T15:59:43.735270Z",
     "iopub.status.idle": "2025-03-15T15:59:43.740945Z",
     "shell.execute_reply": "2025-03-15T15:59:43.740063Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.735517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import (\n",
    "    LongformerModel,\n",
    "    LongformerTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.742236Z",
     "iopub.status.busy": "2025-03-15T15:59:43.741922Z",
     "iopub.status.idle": "2025-03-15T15:59:43.770397Z",
     "shell.execute_reply": "2025-03-15T15:59:43.769405Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.742209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1k.csv\")\n",
    "df = df[[\"text\", \"multi_labels\", \"hier_label\"]]\n",
    "# df['multi_labels'] = df['multi_labels'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.771767Z",
     "iopub.status.busy": "2025-03-15T15:59:43.771431Z",
     "iopub.status.idle": "2025-03-15T15:59:43.778584Z",
     "shell.execute_reply": "2025-03-15T15:59:43.777726Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.771738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def list_ebal(df):\n",
    "    # Преобразуем строки меток в списки (если они ещё не списки)\n",
    "    df[\"multi_labels\"] = df[\"multi_labels\"].apply(\n",
    "        eval\n",
    "    )  # eval используется для преобразования строки в список\n",
    "    # df['hier_label'] = df['hier_label'].apply(eval)  # аналогично для иерархических меток\n",
    "    return df\n",
    "\n",
    "\n",
    "df = list_ebal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.779880Z",
     "iopub.status.busy": "2025-03-15T15:59:43.779615Z",
     "iopub.status.idle": "2025-03-15T15:59:43.807649Z",
     "shell.execute_reply": "2025-03-15T15:59:43.806777Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.779844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.808763Z",
     "iopub.status.busy": "2025-03-15T15:59:43.808481Z",
     "iopub.status.idle": "2025-03-15T15:59:43.823422Z",
     "shell.execute_reply": "2025-03-15T15:59:43.822453Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.808730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. Определяем модель\n",
    "# ================================\n",
    "\n",
    "\n",
    "class HierarchicalMultiTaskLongformer(nn.Module):\n",
    "    def __init__(self, model_name, num_multi_labels, num_hier_labels):\n",
    "        \"\"\"\n",
    "        :param model_name: имя предобученной модели, например, \"allenai/longformer-base-4096\"\n",
    "        :param num_multi_labels: число классов для мультилейблинга\n",
    "        :param num_hier_labels: число классов для иерархической классификации\n",
    "        \"\"\"\n",
    "        super(HierarchicalMultiTaskLongformer, self).__init__()\n",
    "        self.longformer = LongformerModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # Голова для мультилейблинга\n",
    "        self.multi_label_classifier = nn.Linear(\n",
    "            self.longformer.config.hidden_size, num_multi_labels\n",
    "        )\n",
    "        # Голова для иерархической классификации\n",
    "        self.hierarchical_classifier = nn.Linear(\n",
    "            self.longformer.config.hidden_size, num_hier_labels\n",
    "        )\n",
    "        # Функции потерь\n",
    "        self.multi_label_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.hierarchical_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, multi_labels=None, hier_labels=None):\n",
    "        outputs = self.longformer(input_ids, attention_mask=attention_mask)\n",
    "        # Используем представление первого токена ([CLS])\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        ml_logits = self.multi_label_classifier(cls_output)\n",
    "        hier_logits = self.hierarchical_classifier(cls_output)\n",
    "\n",
    "        loss = None\n",
    "        if multi_labels is not None and hier_labels is not None:\n",
    "            ml_loss = self.multi_label_loss_fn(ml_logits, multi_labels)\n",
    "            hier_loss = self.hierarchical_loss_fn(hier_logits, hier_labels)\n",
    "            loss = ml_loss + hier_loss  # Можно добавить веса для балансировки\n",
    "        return ml_logits, hier_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.824677Z",
     "iopub.status.busy": "2025-03-15T15:59:43.824434Z",
     "iopub.status.idle": "2025-03-15T15:59:43.842884Z",
     "shell.execute_reply": "2025-03-15T15:59:43.842197Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.824647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. Определяем Dataset для новостных данных\n",
    "# ================================\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length, mlb, hier_label_map):\n",
    "        \"\"\"\n",
    "        :param dataframe: DataFrame с колонками 'text', 'multi_labels', 'hier_label'\n",
    "        :param tokenizer: токенизатор модели\n",
    "        :param max_length: максимальная длина последовательности\n",
    "        :param mlb: объект MultiLabelBinarizer для мультилейблинга\n",
    "        :param hier_label_map: словарь для маппинга иерархических меток в числа\n",
    "        \"\"\"\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.mlb = mlb\n",
    "        self.hier_label_map = hier_label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        text = row[\"text\"]\n",
    "        # Токенизация текста\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].squeeze()  # [max_length]\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze()  # [max_length]\n",
    "\n",
    "        # Преобразуем мультиметочные метки в бинарный вектор\n",
    "        multi_labels = self.mlb.transform([row[\"multi_labels\"]])[0]\n",
    "        multi_labels = torch.tensor(multi_labels, dtype=torch.float)\n",
    "\n",
    "        # Преобразуем иерархическую метку в числовое значение\n",
    "        hier_label_str = row[\"hier_label\"]\n",
    "        hier_label = self.hier_label_map[hier_label_str]\n",
    "        hier_label = torch.tensor(hier_label, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"multi_labels\": multi_labels,\n",
    "            \"hier_labels\": hier_label,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.843916Z",
     "iopub.status.busy": "2025-03-15T15:59:43.843700Z",
     "iopub.status.idle": "2025-03-15T15:59:43.862485Z",
     "shell.execute_reply": "2025-03-15T15:59:43.861788Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.843897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. Загрузка данных и подготовка разметки\n",
    "# ================================\n",
    "def create_hier_label_map(df):\n",
    "    \"\"\"Создаём маппинг для иерархических меток.\"\"\"\n",
    "    unique_hier_labels = (\n",
    "        df[\"hier_label\"].explode().unique()\n",
    "    )  # Разворачиваем списки и находим уникальные метки\n",
    "    hier_label_map = {label: idx for idx, label in enumerate(unique_hier_labels)}\n",
    "    return hier_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.863685Z",
     "iopub.status.busy": "2025-03-15T15:59:43.863393Z",
     "iopub.status.idle": "2025-03-15T15:59:43.879038Z",
     "shell.execute_reply": "2025-03-15T15:59:43.878118Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.863655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. Тренировочный цикл\n",
    "# ================================\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, optimizer, scheduler, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            multi_labels = batch[\"multi_labels\"].to(device)\n",
    "            hier_labels = batch[\"hier_labels\"].to(device)\n",
    "\n",
    "            ml_logits, hier_logits, loss = model(\n",
    "                input_ids, attention_mask, multi_labels, hier_labels\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:43.880312Z",
     "iopub.status.busy": "2025-03-15T15:59:43.880021Z",
     "iopub.status.idle": "2025-03-15T15:59:46.105950Z",
     "shell.execute_reply": "2025-03-15T15:59:46.104632Z",
     "shell.execute_reply.started": "2025-03-15T15:59:43.880291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Параметры обучения\n",
    "model_name = \"allenai/longformer-base-4096\"\n",
    "max_length = 512\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Создаём маппинг для иерархических меток\n",
    "hier_label_map = create_hier_label_map(df)\n",
    "num_hier_labels = len(hier_label_map)\n",
    "\n",
    "# Определяем фиксированный набор классов для мультилейблинга (знаем заранее)\n",
    "# Получаем уникальные элементы\n",
    "unique_elements = list(\n",
    "    set([item for sublist in df[\"multi_labels\"] for item in sublist])\n",
    ")\n",
    "all_multi_labels = unique_elements\n",
    "mlb = MultiLabelBinarizer(classes=all_multi_labels)\n",
    "mlb.fit(df[\"multi_labels\"])\n",
    "num_multi_labels = len(all_multi_labels)\n",
    "\n",
    "# Инициализируем токенизатор и модель\n",
    "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = HierarchicalMultiTaskLongformer(model_name, num_multi_labels, num_hier_labels)\n",
    "model.to(device)\n",
    "\n",
    "# Создаём Dataset и DataLoader\n",
    "dataset = NewsDataset(df, tokenizer, max_length, mlb, hier_label_map)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:59:49.817955Z",
     "iopub.status.busy": "2025-03-15T15:59:49.817646Z",
     "iopub.status.idle": "2025-03-15T16:01:57.055575Z",
     "shell.execute_reply": "2025-03-15T16:01:57.054665Z",
     "shell.execute_reply.started": "2025-03-15T15:59:49.817928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Оптимизатор и scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "trained_model = train_model(model, dataloader, optimizer, scheduler, device, epochs)\n",
    "\n",
    "# Сохраняем веса модели\n",
    "torch.save(trained_model.state_dict(), \"fine_tuned_longformer.pt\")\n",
    "print(\"Модель сохранена как fine_tuned_longformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:02:43.722963Z",
     "iopub.status.busy": "2025-03-15T16:02:43.722664Z",
     "iopub.status.idle": "2025-03-15T16:02:47.598574Z",
     "shell.execute_reply": "2025-03-15T16:02:47.597502Z",
     "shell.execute_reply.started": "2025-03-15T16:02:43.722936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import LongformerTokenizer\n",
    "\n",
    "# Параметры модели (эти параметры должны соответствовать тем, что использовались при обучении)\n",
    "model_name = \"allenai/longformer-base-4096\"\n",
    "num_multi_labels = num_multi_labels  # например, если у нас 5 меток для мультилейблинга\n",
    "num_hier_labels = (\n",
    "    num_hier_labels  # например, если у нас 3 класса для иерархической классификации\n",
    ")\n",
    "\n",
    "# Инициализация модели и загрузка сохранённых весов\n",
    "model = HierarchicalMultiTaskLongformer(model_name, num_multi_labels, num_hier_labels)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"fine_tuned_longformer.pt\", map_location=torch.device(\"cpu\"), weights_only=False\n",
    "    )\n",
    ")\n",
    "model.eval()  # Переводим модель в режим инференса\n",
    "\n",
    "# Инициализация токенизатора\n",
    "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Пример входного текста\n",
    "sample_text = \"Новая экономическая инициатива обсуждается на высшем уровне.\"\n",
    "\n",
    "# Токенизация текста\n",
    "inputs = tokenizer(\n",
    "    sample_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "# Выполнение инференса (без вычисления градиентов)\n",
    "with torch.no_grad():\n",
    "    ml_logits, hier_logits, _ = model(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]\n",
    "    )\n",
    "\n",
    "# Преобразование логитов в вероятности\n",
    "ml_probs = torch.sigmoid(ml_logits)  # Вероятности для мультилейблинга\n",
    "hier_probs = torch.softmax(\n",
    "    hier_logits, dim=1\n",
    ")  # Вероятности для иерархической классификации\n",
    "\n",
    "print(\"Логиты для мультилейблинга:\", ml_logits)\n",
    "print(\"Вероятности для мультилейблинга:\", ml_probs)\n",
    "print(\"Логиты для иерархической классификации:\", hier_logits)\n",
    "print(\"Вероятности для иерархической классификации:\", hier_probs)\n",
    "\n",
    "# Дополнительно: если требуется получить CLS-токен (вектор эмбеддингов)\n",
    "# Его размерность будет [batch_size, hidden_size] (например, [1, 768] для base модели)\n",
    "# Обычно CLS-токен используется внутри модели для классификации, но можно его извлечь так:\n",
    "with torch.no_grad():\n",
    "    outputs = model.longformer(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]\n",
    "    )\n",
    "cls_token_output = outputs.last_hidden_state[:, 0, :]  # Вектор CLS токена\n",
    "print(\"Вектор CLS токена:\", cls_token_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T16:02:55.972343Z",
     "iopub.status.busy": "2025-03-15T16:02:55.971979Z",
     "iopub.status.idle": "2025-03-15T16:02:57.513632Z",
     "shell.execute_reply": "2025-03-15T16:02:57.512770Z",
     "shell.execute_reply.started": "2025-03-15T16:02:55.972306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Пример входного текста\n",
    "sample_text = \"Пираты напали на судно  и похитили трех членов экипажа, после чего в перестрелке убили четырех сотрудников спасательной группы ВМС страны, сообщают местные СМИ.\"\n",
    "# Токенизация текста\n",
    "inputs = tokenizer(\n",
    "    sample_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_length,\n",
    ")\n",
    "# Переносим тензоры на устройство\n",
    "inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "\n",
    "# Выполняем инференс\n",
    "with torch.no_grad():\n",
    "    ml_logits, hier_logits, _ = model(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]\n",
    "    )\n",
    "\n",
    "# Обработка результатов для мультилейблинга\n",
    "hier_label_names = [\n",
    "    label for label, idx in sorted(hier_label_map.items(), key=lambda x: x[1])\n",
    "]\n",
    "ml_probs = torch.sigmoid(ml_logits)[0]  # [num_multi_labels]\n",
    "threshold = 0.5\n",
    "predicted_multi_labels = [\n",
    "    all_multi_labels[i] for i, prob in enumerate(ml_probs) if prob > threshold\n",
    "]\n",
    "\n",
    "# Обработка результатов для иерархической классификации\n",
    "hier_probs = torch.softmax(hier_logits, dim=1)[0]  # [num_hier_labels]\n",
    "predicted_hier_index = torch.argmax(hier_probs).item()\n",
    "predicted_hier_label = hier_label_names[predicted_hier_index]\n",
    "\n",
    "# Извлекаем вектор CLS токена\n",
    "with torch.no_grad():\n",
    "    outputs = model.longformer(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]\n",
    "    )\n",
    "cls_token_vector = outputs.last_hidden_state[\n",
    "    :, 0, :\n",
    "]  # размер: [batch_size, hidden_size]\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Предсказанные метки для мультилейблинга:\")\n",
    "print(predicted_multi_labels)\n",
    "print(\"\\nВероятности для мультилейблинга:\")\n",
    "for label, prob in zip(all_multi_labels, ml_probs.tolist()):\n",
    "    print(f\"{label}: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nПредсказанная метка для иерархической классификации:\")\n",
    "print(predicted_hier_label)\n",
    "print(\"\\nВероятности для иерархической классификации:\")\n",
    "for label, prob in zip(hier_label_names, hier_probs.tolist()):\n",
    "    print(f\"{label}: {prob:.4f}\")\n",
    "\n",
    "print(\"\\nВектор CLS токена:\")\n",
    "print(cls_token_vector)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6877483,
     "sourceId": 11041120,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
